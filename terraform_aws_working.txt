Terraform + Aws

1) download and install terraform unzip it and copy the address and set it to environment variables

windows << edit environment variables << environment variables << path << double -click New << add the path << open cmd and type (terraform version) to validate

2) download and install aws cli << open cmd and type (aws --version) to validate

3) create aws free account

i) After root user is created add MFA
ii) Go to Users << create user << Select add user to group option << create group (search admin and select policy name with AdministratorAccess and 	
Description with Provides full access to AWS services and resources).
iii) Create user
iv) Logout from root user and login using the newly created user << Add MFA 

4) OPen Visual Code << create a directory where all your files will be kept (TF-AWS) 

5) Set the environment path
$env:Path = [System.Environment]::GetEnvironmentVariable("Path","Machine")

6) run (aws iam list-users)
It would give some key credentials related error To fix this go to AWS Console << Users << select the available user(tf-user) go to Security credentials
 << Create Acces Key << Command Line Interface (CLI) << give any tag name << Create access key.
 
7) set the environment for access key
$Env:AWS_ACCESS_KEY_ID="AKIA5FUFRZJTOGBEDBLZ"
$Env:AWS_SECRET_ACCESS_KEY="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"

8) Run (aws iam list-users) it will generate below output
{
    "Users": [
        {
            "Path": "/",
            "UserName": "tf-user",
            "UserId": "AIDA5FUFRZJTLZMXVPB7O",
            "Arn": "arn:aws:iam::905444444774:user/tf-user",
            "CreateDate": "2025-06-19T13:59:58+00:00",
            "PasswordLastUsed": "2025-06-19T14:03:38+00:00"
        }
    ]
}


8) Let's create a EC2 instance first with console

Go to EC2 << Launch Instance << Name << AMI (which OS to be used in this case linux) << Instance type (t3.micro as this is free) << Key pair << Create key pair
<< Key pair name << Key pair type (RSA) << private key format (.pem) this would be download file a pem file << Network Settings << Create security group << Allow SSH traffic(Anywhere)
<< Select all other options as default << Launch instance..


 9) For creating an instance with the help of terraform follow below steps

(i) Add extension required to code for terraform. Find the extension tab in visual code and search (HarshiCorp terraform) and then select install
(ii) Go to (https://registry.terraform.io/browse/providers) and then go to AWS providers << then use provider 
(iii) Create another directory inside TF-AWS < aws-ec2.
(iv) After creating the directory create a .tf file and include the sample code from the teraform registry provider.



10) After copying the code make necessary changes to the code as required like AMI Id, instance class, location etc...

terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = "6.0.0"
    }
  }
}

provider "aws" {
  # Configuration options
 region = "eu-north-1"
}

resource "aws_instance" "mytestserver2" {
  ami = "ami-0989038dff76173d3"
  instance_type = "t3.micro"

  tags = {
    Name = "mytestserver2"
  }
}

11) To execute this code you need to intialize (init) the terraform package so that AWS is aware and can make necessary changes from here

On the sub-directory(aws-ec2) created under main folder (TF-AWS) right click and run 
(i) terraform init - to intialize provider plugins
(ii) teraform validate - to validate the syntax of the code.
(iii) terraform plan - to compile the terraform code and look for any errors
(iv) terraform apply - this will use the above code and create the instance.
(v) terraform destroy - this will destroy all the instance running on the AWS environment


12) We can also move the .tfstate file in cloud through which it can be accessed globally

==> .tfstate or terraform state helps terraform to know the current values of the parameters used (e.g if you change the instance class from micro to nano it will first
delete the current instance and the new instance will be create with nano class.



13.) Terraform Variables

A variable in terraform is used to store the values of resources which needs to used in mulitples places (e.g region,resources,ami, etc...)

provider "aws" {																		
  # Configuration options																
 region = var.region 																	
}																						

====>>>  Here under provider block the "region" can't be change under this 
	     block as "region" is aws parameter hence we can create a file 
		 "region.tf" and inside that file we have varible declared and that
		  variable would be called using "var.region".
		  



resource "aws_instance" "mytestserver1" {								
  ami           = var.ami_linux                                         
  instance_type = var.instance_type_micro                               
                                                                        
  tags = {
    Name = "mytestserver1"
  }
}

====>>>  Here under resource block the "ami" and "instance_type" parameter can't be renamed 
  block under "resource" are those are aws predefined parameter.We can create a file 
 "ami.tf" and "instance.tf" inside that file we have varible declared and that
  variable would be called using "var.ami_linux" and "var.instance_type_micro".
 
---------------------------------------------------------------------------------


resource "aws_instance" "mytestserver2" {								
  ami           = var.ami_windows                                       
  instance_type = var.instance_type_nano                                
                                                                        
  tags = {
    Name = "mytestserver2"
  }
}

====>>>  Here under resource block the "ami" and "instance_type" parameter can't be renamed 
  block under "resource" are those are aws predefined parameter.We can create a file 
 "ami.tf" and "instance.tf" inside that file we have varible declared and that
  variable would be called using "var.ami_windows" and "var.instance_type_nano".

==========================================================================================================================================

(Note :- Inside "ami.tf" we have two variables)

1.)

variable "ami_linux" {
  description = "AMI ID for Linux instances"
  type        = string
  default     = "ami-05fcfb9614772f051" # Example AMI ID, replace with a valid one for your region
  
}

2.)

variable "ami_windows" {
  description = "AMI ID for Windows instances"
  type        = string
  default     = "ami-01998fe5b868df6e3" # Example AMI ID, replace with a valid one for your region
  
}

==============================================================================================================================================

(Note :- Inside "instance.tf" we have two variables)

1.) 

variable "instance_type_micro" {
  description = "Type of EC2 instance"
  type        = string
  default     = "t3.micro"
  }

2.)

variable "instance_type_nano" {
  description = "Type of EC2 instance"
  type        = string
  default     = "t3.nano"
  }
  

14.) For creating bucket 

resource "aws_s3_bucket" "mybucket" {
  bucket = "mybucketdemo1725
}


"mybucket" is the block name and inside the block "bucket" = your bucket name

15.) For adding file from same location to a bucket

  resource "aws_s3_object" "bucket-data1" {
  bucket = aws_s3_bucket.mybucket.bucket
  # The source file to upload to the S3 bucket
  source = "./myfile.txt"
  # Here the file is kept under same directory in this case it is aws-ec2 hence to
  # take the file from same directory use ./filename
  # If the file is kept in some other directory then use the full path of the file
  key = "mydata.txt"
  #key is the name of the file in the S3 bucket
}


16.) For adding file from diff location and create a directory inside the s3 bucket

  resource "aws_s3_object" "bucket-data2" {
  bucket = aws_s3_bucket.mybucket.bucket
  # The source file to upload to the S3 bucket
  source = "./s3files/testfile.txt"
  # If the file is kept in some other directory then use the relative path from the current module
  # For example, if the file is in a subdirectory called s3files, use ./s3files/testfile.txt
  key = "/new-folder/mydata1.txt"
  #key is the name of the file in the S3 bucket and in this case it will create a new folder
  # and put the file in that folder
}


17.) For creatring a s3 bucket we need to give unique name which should be unique in enitre 
     AWS region to avoid this problem we have RANDOM function

    i.) Add the below provider for RANDOM in terraform block

    terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = "6.0.0"
    }
    # The random provider is used to generate random values, such as passwords or unique identifiers
    # It is often used in conjunction with other resources to ensure that certain attributes are unique or
    # randomly generated.
    # For example, you might use the random provider to generate a random password for an AWS
    random = {
      source = "hashicorp/random"
      version = "3.7.2"
    }
  }
}

ii.) For using RANDOM function we need to call the RANDOM function in resource

#random_id

resource "random_id" "r_id" {

  # The random_id resource generates a random value that can be used in other resources.
  # It is often used to create unique identifiers or random strings.
  byte_length = 8
}

"r_id" is the block name "random_id" is using random id it will generate a random id similarly
like id we having diff methods e.g integer,passwords,bytes...


18.) Here we are creating a bucket using random id in prefix of the bucket name "mybucketdemo"

resource "aws_s3_bucket" "mybucket" {
  bucket = "mybucketdemo${random_id.r_id.hex}" # r.id is the block name of the resource "random_id"  #"mybucketdemo" is a static name for the bucket, and the random_id.r_id.hex
  # r_id.hex is a random hexadecimal string generated by the random_id resource.
  # This ensures that the bucket name is unique across all AWS accounts.
}


=====>>> "${random_id.r_id.hex}" - random_id is the function r_id is the block name and hex is the hexadecimal
value that the query will generate a hexadecimal value and include in the suffix of the bucket name.


--------------------------------------

TERRAFORM REMOTE STATE MANAGEMENT

19. Create a seperate folder called << tf-backend

Here create a remote_state_management.tf terraform file this folder will contain the tfstate 
file which can be used later by anyone to make use of the same config this will be stored in 
s3 bucket


terraform {
    required_providers {
        aws = {
        source  = "hashicorp/aws"
        version = "6.0.0"
        }
    }
        backend "s3" {
            bucket         = "mybucketdemofe0efc95d074af56"
            key            = "remote_state_management.tfstate" # Path within the bucket
            region         = "eu-north-1" # Replace with your desired region
        }
    
}

provider "aws" {
  region = "eu-north-1"

}

resource "aws_instance" "remote-state" {
  ami = "ami-0c55b159cbfafe1f0" # Example AMI, replace with your desired AMI
  instance_type = "t3.nano" # Example instance type, replace with your desired type
  tags = {
    Name = "RemoteStateManagement"
  }  
}


=================================================================================

20.) Create a new folder for static website

i.) Create a index.html and style.css requried for website hosting

<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Document</title>
</head>

<body>
    <h1>This is a Design Version V8</h1>
    <p>Welcome to Terraform Tutorial</p>
</body>

</html>
============================

/* styles.css */
body {
    /* Set a gradient background from purple to teal */
    background: linear-gradient(to right, #6a3093, #a044ff, #5f2c82, #49a09d);
    font-family: Arial, sans-serif;
    /* Sets a clean, modern font for the body text */
    color: white;
    /* Sets the text color to white for better contrast */
    margin: 0;
    /* Removes default margin */
    padding: 0;
    /* Removes default padding */
    display: flex;
    /* Enables flexbox layout */
    justify-content: center;
    /* Centers content horizontally */
    align-items: center;
    /* Centers content vertically */
    height: 100vh;
    /* Makes the body take the full height of the viewport */
}

h1 {
    font-size: 2em;
    /* Sets the size of the header text */
    text-align: center;
    /* Centers the header text */
}


ii.) Create a main.tf containing instance creation,s3 bucket creation,website hosting etc..

terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "6.0.0"
    }
   
  }
}


provider "aws" {
  # Configuration options
  region = "eu-north-1"
}

# This Terraform configuration sets up a static website hosted on an S3 bucket
resource "aws_instance" "static_website_instance" {
  ami           = "ami-00c8ac9147e19828e" # Example AMI ID for Amazon Linux 2
  instance_type = "t3.micro"

  tags = {
    "Name" = "StaticWebsiteInstance"
  }
}


resource "aws_s3_bucket" "static_website_bucket" {
  bucket = "mystaticbucket-staticwb128725" # Unique bucket name across all AWS accounts and region
}

resource "aws_s3_bucket_public_access_block" "static_website_bucket_block" { 
  # This resource blocks public access to the S3 bucket
  # It is important to block public access to prevent unauthorized access to the bucket
  bucket = aws_s3_bucket.static_website_bucket.id
  # The block_public_acls, block_public_policy, ignore_public_acls, and restrict_public_buckets
  # attributes are used to control public access to the bucket.
  block_public_acls       = false
  block_public_policy     = false
  ignore_public_acls      = false
  restrict_public_buckets = false
}

resource "aws_s3_bucket_policy" "static_website_bucket_policy" {
  # This resource defines a bucket policy for the S3 bucket
  # The bucket policy allows public read access to the objects in the S3 bucket
  # The bucket policy is applied to the S3 bucket using the bucket attribute
  # The bucket attribute specifies the S3 bucket to which the policy applies
  bucket = aws_s3_bucket.static_website_bucket.id
  # This resource defines a bucket policy that allows public read access to the objects in the S3 bucket
  # The policy allows anyone to perform the s3:GetObject action on the objects in the
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Principal = "*"
        Action = "s3:GetObject"
        Resource = "arn:aws:s3:::${aws_s3_bucket.static_website_bucket.id}/*"
      }
      # This statement allows public read access to the objects in the S3 bucket
      # The Principal is set to "*" which means anyone can access the objects 
      # The Action is set to "s3:GetObject" which allows read access to the objects
      # The Resource is set to the ARN of the S3 bucket with a wildcard (*) at the end  
      # to allow access to all objects in the bucket.
    ]
  })
}


resource "aws_s3_object" "index_html" {
  # This resource uploads the index.html file to the S3 bucket
  # The index.html file is the main page of the static website
  bucket = aws_s3_bucket.static_website_bucket.bucket
  # The bucket attribute specifies the S3 bucket to which the object is uploaded
  # The source attribute specifies the local file path of the index.html file
  source = "./index.html"
  key    = "index.html"
}


resource "aws_s3_object" "style_css" {
  # This resource uploads the style.css file to the S3 bucket
  # The style.css file contains the styles for the static website
  bucket = aws_s3_bucket.static_website_bucket.bucket
  # The bucket attribute specifies the S3 bucket to which the object is uploaded
  # The source attribute specifies the local file path of the style.css file
  source = "./style.css"
  key    = "style.css"
}